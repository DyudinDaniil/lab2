В папке присутсвуют два файла с реализацией лабораторной работы. main.c - реализация с помощью MPI, а mainPthread.c - реализация с помощью pthread. К сожалению в процессе работы возникли проблемы с Linux и не получилось полностью протестировать версию с MPI, поэтому было принято решение написать ананлог на pthread. Извиняемся за неудобства и надеямся, что у вас получистя запусить версию с MPI)))

### Анализ программы для матричного умножения по алгоритму Кэннона с использованием MPI

#### Введение
Алгоритм матричного умножения по методу Кэннона — это эффективный способ распределенного умножения матриц, который использует разбиение на блоки и обмен данными между процессами. В данной лабораторной работе реализуется этот алгоритм с использованием библиотеки MPI (Message Passing Interface) для параллельных вычислений.

#### Описание алгоритма
Алгоритм Кэннона работает следующим образом:
1. Разбиение матриц: Исходные матрицы A и B разбиваются на блоки фиксированного размера, которые распределяются между процессами.
2. Сдвиг блоков: Каждый процесс выполняет сдвиг своего блока матрицы A влево и блока матрицы B вверх, чтобы подготовить данные для умножения.
3. Умножение блоков: После сдвига каждый процесс умножает свой блок матрицы A на блок матрицы B и добавляет результат в соответствующий блок матрицы C.
4. Обмен данными: Процессы обмениваются блоками с соседями для выполнения умножения на всех блоках матриц.
5. Сбор результатов: После завершения всех вычислений результаты собираются и формируется итоговая матрица C.

#### Замеры времени
В программе используется функция MPI_Wtime() для измерения времени выполнения алгоритма. Время фиксируется до и после выполнения всех операций, что позволяет оценить общую продолжительность выполнения программы. 

#### Ускорение
Ускорение определяется как отношение времени выполнения последовательной версии алгоритма к времени выполнения параллельной версии. Это можно выразить формулой:

[
S = \frac{T{seq}}{T{par}}
\]

где:
- \(S\) — ускорение,
- \(T{seq}\) — время выполнения последовательной версии,
- \(T{par}\) — время выполнения параллельной версии.

#### Анализ производительности
1. Влияние размерности задачи: Увеличение размерности матриц приводит к увеличению объема вычислений и, как следствие, к увеличению времени выполнения. Однако, благодаря параллельной обработке, время выполнения должно расти медленнее, чем в последовательной версии.
2. Влияние количества процессов: Увеличение числа процессов должно приводить к снижению времени выполнения, так как задачи распределяются между большим количеством вычислительных единиц. Однако, после определенного момента, увеличение числа процессов может привести к уменьшению производительности из-за накладных расходов на обмен данными и синхронизацию.
3. Эффективность использования ресурсов: Важно учитывать, что не все задачи могут быть эффективно распараллелены. Для достижения максимальной производительности необходимо оптимальное соотношение между размером задачи и количеством процессов.

#### Заключение
Реализация алгоритма матричного умножения по методу Кэннона с использованием MPI демонстрирует преимущества параллельных вычислений в задачах, требующих значительных вычислительных ресурсов. Замеры времени и анализ ускорения показывают, что при правильной настройке и оптимизации алгоритм может значительно ускорить выполнение задач по сравнению с последовательными методами. Однако следует учитывать, что эффективность параллельных вычислений зависит от множества факторов, включая размерность задачи, количество процессов и архитектуру вычислительной системы.